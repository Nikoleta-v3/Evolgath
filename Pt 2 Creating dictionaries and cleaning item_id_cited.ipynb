{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import glob # forgot what for?...\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d68292",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_items = pd.read_csv(r'.\\data_evolutionary_game_theory\\items_scp_evolgath_202302021205.csv', index_col=None)\n",
    "scp_abstracts = pd.read_csv(r'.\\data_evolutionary_game_theory\\abstracts_scp_evolgath_202302021207.csv', index_col=None)\n",
    "scp_refs = pd.read_csv(r'.\\data_evolutionary_game_theory\\refs_scp_evolgath_202302021207.csv', index_col=None)\n",
    "wos_items = pd.read_csv(r'.\\data_evolutionary_game_theory\\items_wos_evolgath_202301271505.csv', index_col=None)\n",
    "wos_abstracts = pd.read_csv(r'.\\data_evolutionary_game_theory\\abstracts_wos_evolgath_202301271503.csv', index_col=None)\n",
    "wos_refs = pd.read_csv(r'.\\data_evolutionary_game_theory\\refs_wos_evolgath_202301271505.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1790a",
   "metadata": {},
   "source": [
    "Start first steps for perspective networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scp_items.loc[:,'item_title'] #only title column\n",
    "wos_items.loc[:,'item_title'] #only title column\n",
    "scp_items['item_title'].equals(wos_items['item_title']) #scp and wos do not hold the same publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which titles are included in both scp and wos?\n",
    "list(set(scp_items.item_title) & set(wos_items.item_title)) \n",
    "#common values, Check whether scp is included within wos? or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4747bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which item_id do certain titles hold?\n",
    "scp_items.loc[scp_items['item_title'] == 'The N-Player Trust Game and its Replicator Dynamics', 'item_id']\n",
    "wos_items.loc[wos_items['item_title'] == 'The N-Player Trust Game and its Replicator Dynamics', 'item_id'] \n",
    "#item_id format is different for wos and scp\n",
    "\n",
    "# For later: How to handle scp and wos differences? For now, wos apparently holds more titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055ad11",
   "metadata": {},
   "source": [
    "Filter for duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_items.item_id.nunique() # 1501\n",
    "wos_refs.item_id_cited.nunique() #unique IDs for cited articles # 38708\n",
    "#does this mean that the number of relevant work for the field is not too big?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89855cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_refs['edited_title'] = wos_refs.ref_item_title.str.lower() #create new column with all titles in lower-case\n",
    "wos_refs.loc[:,'edited_title'] #check whether lower-casing has worked; yes! Length: 59935\n",
    "wos_refs.ref_item_title.nunique() #how many different titles would there be unedited? # 29667\n",
    "wos_refs.edited_title.nunique() #how many different titles left when edited to lower-case?\n",
    "# Length: only 29443!! (nunique drops NA by default, if not wanted, add dropna=False)\n",
    "wos_refs['edited_title'].isna().sum() # 8435\n",
    "wos_refs.edited_title.nunique(dropna=False) # NA counts as 1 # 29444\n",
    "series = wos_refs.groupby(\"item_id_cited\")['item_id_citing'].nunique() #group the cited id by the citing id!\n",
    "print(series) # same output as for wos_refs.item_id_cited.nunique(), makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc08e770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(series.values, bins=100);\n",
    "\n",
    "#plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b013e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.loc[series.values > 1] #cited more than once # 5291\n",
    "wos_refs.loc[wos_refs.item_id_cited.isin(series.loc[series.values > 1].index)] \n",
    "#get where item_id_cited is in the series of cited more often than once\n",
    "\n",
    "#do the following after we know about duplicates # EDIT: DONT!\n",
    "#wos_refs[['item_id_cited', 'ref_pubyear', 'ref_authors']].drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictedtit={} #create an empty dictionary\n",
    "for index,s in wos_refs.iterrows(): #loop over rows in our df\n",
    "    if s['edited_title'] in dictedtit: #if title already exists in our created dictionary\n",
    "        if s['item_id_cited'] not in dictedtit[s['edited_title']]: #and id_item_cited is still not present in our dictionary\n",
    "            dictedtit[s['edited_title']].append(s['item_id_cited']) #then append the id_item_cited to the existing title\n",
    "    else: \n",
    "        dictedtit[s['edited_title']] = [s['item_id_cited']] #if not, then create new key title with item_id_cited as a value\n",
    "        \n",
    "len(dictedtit) # 29444\n",
    "print(dictedtit['toward a metabolic theory of ecology']) # testwise, gives item id cited for this title ['WOS:000223113500001']\n",
    "# print(dictedtit) # IOPub data rate exceeded\n",
    "\n",
    "print(list(dictedtit.items())[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df77c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdict = {k: dictedtit[k] for k in list(dictedtit)[:20]}\n",
    "# trying out how to get only some entries of the dictionary\n",
    "print(newdict) #gives chunk of 20 titles\n",
    "\n",
    "\n",
    "dictduplicate = {k: dictedtit[k] for k in dictedtit if len(dictedtit[k]) > 1} \n",
    "# only key-value pairs with >1 id_item_cited, because others should be fine and no need to relabel\n",
    "print(dictduplicate)\n",
    "len(dictduplicate) # 549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14954e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_refs.isna()\n",
    "print( sorted(dictduplicate.items(), key= lambda x: len(x[1]), reverse=True) )\n",
    "#sort by number of values ()\n",
    "\n",
    "del dictduplicate[np.nan]# nan needs the np in front!!\n",
    "dictduplicatesorted = sorted(dictduplicate.items(), key= lambda x: len(x[1]), reverse=True) \n",
    "# sort by number of values\n",
    "print(dictduplicatesorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed313350",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfduplicated =pd.DataFrame.from_dict(dict(dictduplicatesorted), orient='index') # df for better visibility\n",
    "dfduplicated.to_csv('titles_with_multi_ids.csv', encoding='utf-8')\n",
    "dfduplicated #check only really for the bigger first one, the other ones are most probably the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa62f39",
   "metadata": {},
   "source": [
    "Create replacing dictionary and a new column for the wos_refs df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_refs['item_id_clear'] = wos_refs['item_id_cited'] #clone item_id_cited column to later replace values only in there\n",
    "wos_refs.head() #worked, new column created\n",
    "type(dictduplicate) # dict\n",
    "\n",
    "dictreplace ={v[0]: v[1:] for v in dictduplicate.values()} \n",
    "# ignore keys aka titles; take first id as key, remaining ids until last as values\n",
    "# goal: {'BCI:BCI19522600023673': [\"A\", \"B\"]} \n",
    "dfdictreplace=pd.DataFrame.from_dict(dict(dictduplicatesorted), orient='index') # df for better visibility\n",
    "dfdictreplace\n",
    "# would need double looping through df and value lists, better try rearranging dictionary to long format\n",
    "\n",
    "dictreplace_alt = {i: k for k,v in dictreplace.items() for i in v} # needs .items() wtf, otherwise returns meta stuff\n",
    "# k becomes first id\n",
    "# v is remaining list of other ids\n",
    "\n",
    "# same as:\n",
    "#dictreplace_alt = {}\n",
    "#for k,v in dictreplace.items():\n",
    "#    for i in v:\n",
    "#        dictreplace_alt[i]=k\n",
    "\n",
    "dictreplace_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d051d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_refs2 = wos_refs.replace({'item_id_clear':dictreplace_alt})\n",
    "wos_refs.compare(wos_refs2)\n",
    "\n",
    "# check titles with most ids\n",
    "wos_refs2.loc[wos_refs['edited_title'] == 'evolutionary game theory'] # title needs manual check\n",
    "wos_refs2.loc[wos_refs['edited_title'] == 'stochastic evolutionary game dynamics'] # title needs manual check\n",
    "wos_refs2.loc[wos_refs['edited_title'] == 'population dynamics from game theory'] # all the same\n",
    "wos_refs2.loc[wos_refs['edited_title'] == 'evolutionary game theory: a renaissance'] # all the same\n",
    "wos_refs2.loc[wos_refs['edited_title'] == 'random processes in genetics'] # all the same\n",
    "wos_refs2.loc[wos_refs['edited_title'] == 'the emergence of commitments and cooperation'] # all the same, checked manually, deviation due to changed author order\n",
    "\n",
    "wos_items.item_title.nunique()\n",
    "wos_refs2.item_id_clear.nunique() # 37870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ATTENTION FOR FUTURE VIVI: INDEXING HAPPENING HERE!\n",
    "\n",
    "# manual check for distinct articles with title \"evolutionary game theory\"\n",
    "weibull = [2809,19703,21738,34994,48101,56850] # weibull\n",
    "wos_refs2.loc[weibull,'item_id_clear'] = '000527769700042.48' \n",
    "wos_refs2.at[7354, 'item_id_clear'] = '000498881800052.4' # easley ; this guy's name is not easeley btw, can't find publication\n",
    "sandholm = [8738, 9257, 19512, 52016, 53875] # sandholm\n",
    "wos_refs2.loc[sandholm,'item_id_clear'] = '000296007000001.31'\n",
    "alexander = [12024, 29023, 32574, 37342, 44444, 57100] # J. McKenzie Alexander\n",
    "wos_refs2.loc[alexander,'item_id_clear'] = '000297819200015.9'\n",
    "wos_refs2.at[27274, 'item_id_clear'] = '000607329000002.10' # cressman\n",
    "wos_refs2.at[37946, 'item_id_clear'] = '000525401500057.17' # smith\n",
    "wos_refs2.at[46560, 'item_id_clear'] = '000457952400133.21' # siegmund\n",
    "wos_refs2.at[50085, 'item_id_clear'] = '000441998400054.33' # vincent\n",
    "\n",
    "\n",
    "# manual check for distinct articles with title \"stochastic evolutionary game dynamics\"\n",
    "pd.set_option('display.max_rows', None) # force jupyter notebook to show me all the rows\n",
    "# need to reduce down from 68 rows\n",
    "stoch = wos_refs2.loc[wos_refs2['edited_title'] == 'stochastic evolutionary game dynamics']  # title needs manual check\n",
    "stoch.loc[stoch['item_id_cited'] != 'WOS:A1990EE29600005']\n",
    "# foster authors can keep their given item_id_clear\n",
    "wallace = [9259, 56675] # wallace\n",
    "wos_refs2.loc[wallace,'item_id_clear'] = '000550684000036.11' \n",
    "\n",
    "traulsen = [9911, 10864, 11060, 13370, 16064, 18399, 21053, \n",
    "            21296, 26125, 30109, 34608, 36098, 43663, 47440, 48532, 50225, 58148] # traulsen & hauert \n",
    "wos_refs2.loc[traulsen,'item_id_clear'] = '000705615300001.39' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddd7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns that contain mostly nans\n",
    "wos_refs2 = wos_refs2.drop(columns=['scopus_ref_issue', \n",
    "                        'wos_ref_article_number', \n",
    "                        'scopus_ref_text', \n",
    "                        'scopus_ref_fulltext', \n",
    "                        'wos_citation_context' ])\n",
    "wos_refs2.head() # looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfcca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_refs2.to_csv('wos_refs_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf035e",
   "metadata": {},
   "source": [
    "1: break down and clean notebook!s! 2: clean items table and refs table and export clean csv; columns with mostly NaN can be deleted 3: zaggl paper: replicate section data set description and write it up; look up Gmür 2003 CoCit-value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
